# Research-Intelligence-System
An AI-powered system for analyzing academic research papers. Users can upload PDFs to generate concise summaries, structured insights, and ask context-aware questions using LLMs and semantic search. Built with Streamlit, LangChain, FAISS, and Groq LLaMA models.
ğŸ“š Research Intelligence System

An end-to-end AI-powered research paper analysis system that allows users to upload academic PDFs and interact with them using summarization, semantic search, and question answering.
Built with Python, LangChain, Groq LLMs, FAISS, and Streamlit.

ğŸš€ Features

ğŸ“„ PDF Ingestion

Extracts text from research papers using pdfplumber

Preserves page-level context for accurate referencing

âœ‚ï¸ Smart Chunking

Splits large documents into manageable, overlapping chunks

Enables efficient embedding and retrieval

ğŸ§  Semantic Search & QA

Uses vector embeddings + FAISS for similarity search

Ask natural-language questions about the paper

ğŸ“ LLM-Based Summarization

Short summary of the paper

Structured summary (objective, methodology, findings, conclusion)

ğŸ–¥ï¸ Interactive Streamlit UI

Upload PDFs

Ask questions

Get answers grounded in document content

ğŸ› ï¸ Tech Stack
Component	Technology
Language	Python 3.10
UI	Streamlit
PDF Parsing	pdfplumber
LLM	Groq (LLaMA-3.1-8B)
Framework	LangChain
Vector DB	FAISS
Embeddings	Sentence Transformers
ğŸ“‚ Project Structure
Research_intelligence_system/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”‚   â””â”€â”€ paper_ingestor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ indexing/
â”‚   â”‚   â”œâ”€â”€ chunk_builder.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ summarization/
â”‚   â”‚   â”œâ”€â”€ paper_summarizer.py
â”‚   â”‚   â””â”€â”€ test_summarizer.py
â”‚   â”‚
â”‚   â””â”€â”€ qa/
â”‚       â””â”€â”€ qa_pipeline.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ venv/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/research-intelligence-system.git
cd research-intelligence-system

2ï¸âƒ£ Create & Activate Virtual Environment
python -m venv venv


Windows

venv\Scripts\activate


Mac/Linux

source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Environment Variables

Create a .env file in the root directory:

GROQ_API_KEY=your_groq_api_key_here

â–¶ï¸ Run the Application
python -m streamlit run frontend/app/streamlit_app.py


Then open your browser at:

http://localhost:8501

ğŸ§ª Testing (Optional)

To test summarization independently:

python -m backend.summarization.test_summarizer

ğŸ§  How It Works

User uploads a PDF

Text is extracted page-wise

Document is chunked intelligently

Chunks are embedded and stored in FAISS

User asks a question

Relevant chunks are retrieved

LLM generates an answer grounded in document context

ğŸ“Œ Key Challenges Solved

âœ… Token overflow using chunk-based summarization

âœ… Large PDF handling

âœ… Modular backend architecture

âœ… Streamlit caching for performance

ğŸ”® Future Enhancements

ğŸ” Highlight answer source pages

ğŸ“Š Paper comparison feature

ğŸ§¾ Citation-aware answers

â˜ï¸ Cloud deployment

ğŸ“‘ Multi-document support

ğŸ‘¨â€ğŸ’» Author

Jatin Kanyan
Aspiring Data Scientist | ML & GenAI Enthusiast

ğŸ“ Video Link : https://drive.google.com/file/d/19Ss2O0dE9BbGThm0cau7D-nVXMTYXgmV/view?usp=sharing
ğŸ“ GitHub: https://github.com/jatinkanyan/Research-Intelligence-System

â­ If you like this project

Give it a â­ on GitHub â€” it really helps!
